---
name: fix-review-issues
description: "Orchestrate fixing issues found by $review. Handles issue discovery, user confirmation, plan creation, and execution via $implement. Triggers: fix review issues, fix findings, address review feedback."
---

**User request**: $ARGUMENTS

Systematically address issues found from `$review` runs. Orchestrates: discover issues → confirm scope → plan → execute → verify.

**Flags**: `--autonomous` → skip Phase 2 scope confirmation and Phase 5 next-steps prompt (requires scope args)

## Workflow

### Phase 0: Parse Arguments

Parse `$ARGUMENTS` to determine scope:

| Argument | Effect |
|----------|--------|
| (none) | Fix ALL issues from review |
| `--severity <level>` | Filter by severity (critical, high, medium, low) |
| `--category <type>` | Filter by category (use categories found in review output) |
| File paths | Focus on specific files only |

Multiple filters combine: `--severity critical,high --category <cat1>,<cat2>`

### Phase 1: Discover Review Results

**Step 1**: Check if review results exist in the current conversation context.

**Step 2**: If NO review results found, ask the user:

```
No Review Results Found

I couldn't find recent $review output in this conversation. What would you like to do?
Options:
  - Run $review now - perform a fresh review first
  - Paste review output - I'll provide the review results
  - Cancel - I'll run $review myself first
```

- If "Run $review now": Inform user to run `$review` first, then return to `$fix-review-issues`
- If "Paste review output": Wait for user to provide the review results
- If "Cancel": End the workflow

**Step 3**: If review results ARE found, extract and categorize all issues:

1. Parse each issue for: severity, category, file path, line number, description, suggested fix
2. Group issues by category
3. Count totals by severity

### Phase 2: Confirm Scope with User

**If `--autonomous` OR scope arguments provided** → skip Phase 2, proceed to Phase 3

**If NO arguments** (fix all):

```
Review Issues Summary

Found {N} total issues from the review. What would you like to fix?

[Display: Issue breakdown by category and severity]

Options:
  - Fix all issues (Recommended)
  - Only critical and high severity
  - Only specific categories - let me choose
  - Only specific files - let me specify
```

**If "Only specific categories"**:

Present multi-select with categories found in the review output (dynamically generated from Phase 1 parsing).

**If "Only specific files"**:

```
Specify Files

Which files or directories should I focus on?
(e.g., src/auth/ or src/utils.ts, src/helpers.ts)
```

### Phase 3: Create Fix Plan

Invoke the plan skill to create the implementation plan: `$plan Fix these review issues: [summary of issues within confirmed scope]`

Once the plan is approved, note the plan file path (typically `/tmp/plan-*.md`) and proceed to execution.

### Phase 4: Execute Fixes

Invoke the implement skill to execute the plan: `$implement <plan-file-path>`

The `$implement` skill handles dependency-ordered execution, progress tracking, and auto-fixing gate failures.

### Phase 5: Next Steps

**If `--autonomous`**: Skip prompt, end after implementation completes. Caller handles verification.

**Otherwise**, ask the user:

```
Fixes Complete

Implementation finished. What would you like to do next?
Options:
  - Run $review again - verify fixes are complete (Recommended)
  - Show diff - see all changes made
  - Done - I'll verify manually
```

## Key Principles

- **User Control**: Confirm scope before making changes
- **Reduce Cognitive Load**: Offer clear options with recommended option first
